{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETECCIÓN DE MOVIMIENTO CON OPENCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRAME DIFFERENCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Captura de video desde un archivo\n",
    "ruta_del_video = \"FLUJO OPTICO/MAN_WALK.mp4\"\n",
    "cap = cv2.VideoCapture(ruta_del_video)\n",
    "#cap = cv2.VideoCapture(0)\n",
    "# Leer el primer fotograma\n",
    "ret, frame_anterior = cap.read()\n",
    "frame_anterior = cv2.cvtColor(frame_anterior, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame_actual = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convertir a escala de grises\n",
    "    frame_actual = cv2.cvtColor(frame_actual, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calcular la diferencia absoluta entre fotogramas\n",
    "    diff = cv2.absdiff(frame_anterior, frame_actual)\n",
    "    \n",
    "    # Aplicar umbralización para resaltar el movimiento\n",
    "    _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    cv2.imshow('Diferencia de fotogramas', diff)\n",
    "    cv2.imshow('Movimiento detectado', thresh)\n",
    "    \n",
    "    # Actualizar el fotograma anterior\n",
    "    frame_anterior = frame_actual.copy()\n",
    "    \n",
    "    # Salir con la tecla 'q'\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método es simple:\n",
    "\n",
    "Se captura el video.\n",
    "Se obtiene el fotograma actual y el anterior.\n",
    "Se calcula la diferencia entre ambos.\n",
    "Se aplica umbralización para resaltar el movimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUTRACCION DE FONDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Captura de video desde un archivo\n",
    "ruta_del_video = \"FLUJO OPTICO/MAN_WALK.mp4\"\n",
    "cap = cv2.VideoCapture(ruta_del_video)\n",
    "\n",
    "# Crear el sustractor de fondo (GMM)\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Aplicar la sustracción de fondo\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    cv2.imshow('Frame Original', frame)\n",
    "    cv2.imshow('Sustracción de Fondo', fgmask)\n",
    "    \n",
    "    # Salir con la tecla 'q'\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLUJO OPTICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Captura de video desde un archivo\n",
    "#ruta_del_video = \"FLUJO OPTICO/MAN_WALK.mp4\"\n",
    "#cap = cv2.VideoCapture(ruta_del_video)\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Parámetros para el flujo óptico de Farnebäck\n",
    "params = dict(pyr_scale=0.5, levels=3, winsize=15, iterations=3, poly_n=5, poly_sigma=1.2, flags=0)\n",
    "\n",
    "# Leer el primer fotograma\n",
    "ret, frame_anterior = cap.read()\n",
    "gray_anterior = cv2.cvtColor(frame_anterior, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "hsv = np.zeros_like(frame_anterior)\n",
    "hsv[..., 1] = 255  # Saturación máxima para visualizar mejor\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame_actual = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray_actual = cv2.cvtColor(frame_actual, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calcular flujo óptico de Farnebäck\n",
    "    flow = cv2.calcOpticalFlowFarneback(gray_anterior, gray_actual, None, **params)\n",
    "    \n",
    "    # Convertir a ángulo y magnitud para visualización\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2  # Convertir ángulo a escala de colores\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)  # Normalizar magnitud\n",
    "    \n",
    "    # Convertir HSV a BGR para mostrar\n",
    "    bgr_flow = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    cv2.imshow('Frame Original', frame_actual)\n",
    "    cv2.imshow('Flujo Óptico', bgr_flow)\n",
    "    \n",
    "    # Actualizar el fotograma anterior\n",
    "    gray_anterior = gray_actual.copy()\n",
    "    \n",
    "    # Salir con la tecla 'q'\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DETECCION DE ESQUINAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Captura de video desde un archivo\n",
    "#ruta_del_video = \"FLUJO OPTICO/MAN_WALK.mp4\"\n",
    "#cap = cv2.VideoCapture(ruta_del_video)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detección de esquinas con Harris\n",
    "    gray = np.float32(gray)\n",
    "    corners = cv2.cornerHarris(gray, 2, 3, 0.04)\n",
    "    frame[corners > 0.01 * corners.max()] = [0, 0, 255]  # Marcar esquinas en rojo\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    cv2.imshow('Detección de Esquinas', frame)\n",
    "    \n",
    "    # Salir con la tecla 'q'\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny + Contornos\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "    \n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(frame, contours, -1, (0, 255, 0), 2)  # Dibujar contornos en verde\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    cv2.imshow('Canny + Contornos', frame)\n",
    "    \n",
    "    # Salir con la tecla 'q'\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VISION_ARTIFICIAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
