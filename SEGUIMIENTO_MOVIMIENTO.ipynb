{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE TRACKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def init_tracker():\n",
    "    # Inicializar el detector de características SIFT\n",
    "    feature_detector = cv2.SIFT_create()\n",
    "    \n",
    "    # Inicializar el matcher de características\n",
    "    matcher = cv2.BFMatcher()\n",
    "    \n",
    "    return feature_detector, matcher\n",
    "\n",
    "def track_features(frame1, frame2, feature_detector, matcher):\n",
    "    # Detectar keypoints y descriptores\n",
    "    keypoints1, descriptors1 = feature_detector.detectAndCompute(frame1, None)\n",
    "    keypoints2, descriptors2 = feature_detector.detectAndCompute(frame2, None)\n",
    "    \n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        return [], [], []\n",
    "    \n",
    "    # Encontrar matches entre los descriptores\n",
    "    matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    \n",
    "    # Aplicar test de ratio de Lowe para filtrar buenos matches\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    # Obtener coordenadas de los puntos coincidentes\n",
    "    if len(good_matches) > 0:\n",
    "        pts1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches])\n",
    "        pts2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches])\n",
    "        return pts1, pts2, good_matches\n",
    "    \n",
    "    return [], [], []\n",
    "\n",
    "def main():\n",
    "    # Iniciar captura de video\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Verificar si la cámara se abrió correctamente\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error al abrir la cámara\")\n",
    "        return\n",
    "    \n",
    "    # Obtener el primer frame\n",
    "    ret, prev_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error al leer el primer frame\")\n",
    "        return\n",
    "    \n",
    "    # Convertir a escala de grises\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Inicializar el tracker\n",
    "    feature_detector, matcher = init_tracker()\n",
    "    \n",
    "    while True:\n",
    "        # Leer el siguiente frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        # Convertir a escala de grises\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Realizar el tracking\n",
    "        pts1, pts2, good_matches = track_features(prev_gray, gray, feature_detector, matcher)\n",
    "        \n",
    "        # Dibujar las trayectorias\n",
    "        if len(pts1) > 0:\n",
    "            for pt1, pt2 in zip(pts1, pts2):\n",
    "                # Dibujar una línea entre los puntos coincidentes\n",
    "                cv2.line(frame, tuple(map(int, pt1)), tuple(map(int, pt2)), (0, 255, 0), 2)\n",
    "                # Dibujar un círculo en el punto actual\n",
    "                cv2.circle(frame, tuple(map(int, pt2)), 5, (0, 0, 255), -1)\n",
    "        \n",
    "        # Mostrar el resultado\n",
    "        cv2.imshow('Feature Tracking', frame)\n",
    "        \n",
    "        # Actualizar el frame previo\n",
    "        prev_gray = gray.copy()\n",
    "        \n",
    "        # Salir si se presiona 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Liberar recursos\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTICAL FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def init_tracking_points():\n",
    "    # Parámetros para la detección de esquinas de Shi-Tomasi\n",
    "    feature_params = dict(\n",
    "        maxCorners=100,\n",
    "        qualityLevel=0.3,\n",
    "        minDistance=7,\n",
    "        blockSize=7\n",
    "    )\n",
    "    return feature_params\n",
    "\n",
    "def init_optical_flow():\n",
    "    # Parámetros para el flujo óptico de Lucas-Kanade\n",
    "    lk_params = dict(\n",
    "        winSize=(15, 15),\n",
    "        maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "    )\n",
    "    return lk_params\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Verificar si la cámara se abrió correctamente\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error al abrir la cámara\")\n",
    "        return\n",
    "\n",
    "    # Leer el primer frame\n",
    "    ret, old_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error al leer el primer frame\")\n",
    "        return\n",
    "\n",
    "    # Convertir a escala de grises\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Inicializar parámetros\n",
    "    feature_params = init_tracking_points()\n",
    "    lk_params = init_optical_flow()\n",
    "    \n",
    "    # Crear máscara para dibujar\n",
    "    mask = np.zeros_like(old_frame)\n",
    "    \n",
    "    # Detectar puntos iniciales\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "    \n",
    "    # Crear colores aleatorios para las trayectorias\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if p0 is not None and len(p0) > 0:\n",
    "            # Calcular el flujo óptico\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "                old_gray, \n",
    "                frame_gray, \n",
    "                p0, \n",
    "                None, \n",
    "                **lk_params\n",
    "            )\n",
    "\n",
    "            if p1 is not None:\n",
    "                # Seleccionar puntos buenos\n",
    "                good_new = p1[st == 1]\n",
    "                good_old = p0[st == 1]\n",
    "\n",
    "                # Dibujar las trayectorias\n",
    "                for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                    a, b = new.ravel()\n",
    "                    c, d = old.ravel()\n",
    "                    \n",
    "                    # Dibujar línea entre punto antiguo y nuevo\n",
    "                    mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), \n",
    "                                  color[i % len(color)].tolist(), 2)\n",
    "                    \n",
    "                    # Dibujar círculo en la posición actual\n",
    "                    frame = cv2.circle(frame, (int(a), int(b)), 5, \n",
    "                                     color[i % len(color)].tolist(), -1)\n",
    "                \n",
    "                # Superponer máscara y frame\n",
    "                img = cv2.add(frame, mask)\n",
    "                \n",
    "                # Mostrar resultado\n",
    "                cv2.imshow('Optical Flow', img)\n",
    "                \n",
    "                # Actualizar puntos anteriores\n",
    "                p0 = good_new.reshape(-1, 1, 2)\n",
    "            \n",
    "            # Si se perdieron demasiados puntos, detectar nuevos\n",
    "            if len(good_new) < 10:\n",
    "                p0 = cv2.goodFeaturesToTrack(frame_gray, mask=None, **feature_params)\n",
    "                mask = np.zeros_like(old_frame)\n",
    "\n",
    "        else:\n",
    "            # Si no hay puntos, detectar nuevos\n",
    "            p0 = cv2.goodFeaturesToTrack(frame_gray, mask=None, **feature_params)\n",
    "            mask = np.zeros_like(old_frame)\n",
    "\n",
    "        # Actualizar frame anterior\n",
    "        old_gray = frame_gray.copy()\n",
    "\n",
    "        # Salir si se presiona 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "        # Limpiar trayectorias si se presiona 'c'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('c'):\n",
    "            mask = np.zeros_like(old_frame)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "\n",
    "# Capturar video\n",
    "ruta_del_video = \"FLUJO OPTICO/MAN_WALK.mp4\"\n",
    "cap = cv2.VideoCapture(ruta_del_video)\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Diccionario para almacenar trayectorias\n",
    "trajectories = {}\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    fgmask = fgbg.apply(gray)\n",
    "    \n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for i, cnt in enumerate(contours):\n",
    "        if cv2.contourArea(cnt) > 500:  # Filtrar pequeños ruidos\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            center = (x + w // 2, y + h // 2)\n",
    "            \n",
    "            # Almacenar trayectorias\n",
    "            if i not in trajectories:\n",
    "                trajectories[i] = []\n",
    "            trajectories[i].append(center)\n",
    "            \n",
    "            # Dibujar trayectorias\n",
    "            for j in range(1, len(trajectories[i])):\n",
    "                cv2.line(frame, trajectories[i][j-1], trajectories[i][j], (0, 255, 0), 2)\n",
    "            \n",
    "            # Dibujar el bounding box\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    \n",
    "    cv2.imshow('Frame', frame)\n",
    "    cv2.imshow('Foreground Mask', fgmask)\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VISION_ARTIFICIAL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
